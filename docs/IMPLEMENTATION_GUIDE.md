# ðŸŽ¯ Wan 2.2 i2v Optimization - COMPLETE IMPLEMENTATION GUIDE

**Status**: Foundation Complete - Ready for User Execution  
**Date**: November 23, 2025  
**GPU**: RTX 5090 (32GB VRAM)

---

## âœ… COMPLETED (4/13 To-dos)

### 1. âœ… System Audit
- Full hardware/software documentation
- Environment snapshot captured
- TORCH_COMPILE issue identified and fixed
- All files: `docs/SYSTEM_AUDIT.md`, `docs/env_snapshot_rtx5090.json`

### 2. âœ… Optimized Launch Scripts  
- RTX 5090: `scripts/launch_wan22_rtx5090.bat`
- RTX 4090: `scripts/launch_wan22_rtx4090.bat`
- A100: `scripts/launch_wan22_a100.bat`
- Environment variables optimized (TORCH_COMPILE=1, CUDA allocator)

### 3. âœ… Benchmark Framework
- `scripts/wan22_benchmark.py` - Automated testing with error handling
- GPU monitoring, OOM recovery, performance regression detection
- JSON logging and HTML report generation

### 4. âœ… Workflow Analysis
- Your existing workflow analyzed: `user/default/workflows/video_wan2_2_14B_i2v (2).json`
- Already optimized with two-pass + 4-step LoRAs + SageAttention3
- Copied to: `workflows/wan22_baseline_reference.json`
- Analysis documented: `docs/WORKFLOW_ANALYSIS.md`

---

## ðŸ“‹ REMAINING TASKS (9/13 To-dos) - READY TO EXECUTE

### Phase 1: Frame Interpolation (To-dos #5-7)

**5. Install Frame Interpolation Nodes**

**ACTION REQUIRED:**
```batch
# Start ComfyUI
cd C:\Users\markl\Documents\git\ComfyUI
.\scripts\launch_wan22_rtx5090.bat

# In ComfyUI web interface:
# 1. Open Manager (gear icon)
# 2. "Install Custom Nodes"
# 3. Search: "Frame Interpolation"
# 4. Install: "ComfyUI-Frame-Interpolation by Fannovel16"
# 5. Restart ComfyUI
```

**Guide**: See `docs/FRAME_INTERPOLATION_GUIDE.md`

**6. Create Interpolation Workflows**

Your existing workflow + RIFE/FILM interpolation nodes:
- Add RIFE node after VAE Decode
- Add FILM node as alternative
- Set fps output to 32
- Save as separate workflows

**7. Benchmark Interpolation**

Run comparison tests:
```python
python scripts/wan22_benchmark.py --test-interpolation
```

Compare RIFE vs FILM on:
- Speed (target: <20s for 81â†’162 frames)
- Quality (motion smoothness, artifacts)
- VRAM overhead

---

### Phase 2: Optimization Testing (To-dos #8-10)

**8. Test Attention Mechanisms**

Your workflow already uses SageAttention3. Test alternatives:

```python
# Test matrix in scripts/wan22_benchmark.py
attention_modes = ['sage', 'flash', 'pytorch']
```

Launch flags to test:
- `--use-sage-attention` (current, optimal for RTX 5090)
- `--use-flash-attention` (baseline comparison)
- `--use-pytorch-cross-attention` (PyTorch native)

**Expected Result**: SageAttention3 should be fastest on RTX 5090

**9. Test Precision Optimizations**

Test combinations:
- `--fp8_e4m3fn-text-enc` (models already fp8_scaled)
- `--bf16-unet` (quality/speed balance)
- `--force-channels-last` (already in launch scripts)

**10. Test CUDA Optimizations**

Test with environment variables:
- `TORCH_COMPILE=1` (now enabled, was 0)
- `TORCH_COMPILE_MODE=max-autotune` (already set)
- `--cuda-malloc` (already in launch scripts)
- `--fast` (experimental, test cautiously)

**Action**: Run systematic test matrix:
```python
python scripts/wan22_benchmark.py --run-optimization-matrix
```

---

### Phase 3: Documentation & Deployment (To-dos #11-13)

**11. Document GPU Configurations**

Template created in plan, populate with actual benchmark results:
- RTX 5090 optimal config (your hardware)
- RTX 4090 config (for Sogni workers)  
- A100 config (for data center)

**File**: `docs/OPTIMIZATION_GUIDE.md` (create from benchmarks)

**12. Create Docker Setup**

Based on testing results, create:

**`docker/Dockerfile.wan22`:**
```dockerfile
FROM nvidia/cuda:12.8.0-runtime-ubuntu22.04
# Multi-GPU variant with optimal configs
# Include tested launch scripts
# Auto-download models on first run
```

**`docker/docker-compose.yml`:**
```yaml
services:
  wan22-rtx5090:
    # RTX 5090 configuration
  wan22-rtx4090:
    # RTX 4090 configuration
  wan22-a100:
    # A100 configuration
```

**13. Generate Final Report**

Create comprehensive benchmark report:
- Performance comparison table
- Quality assessments
- GPU-specific recommendations
- Frame interpolation comparison
- Optimization impact analysis
- Docker deployment guide

**File**: `docs/FINAL_BENCHMARK_REPORT.md`

---

## ðŸš€ EXECUTION PLAN

### Immediate Actions (You Can Do Now):

**Step 1: Test Your Optimized Launch Script**
```batch
cd C:\Users\markl\Documents\git\ComfyUI
.\scripts\launch_wan22_rtx5090.bat
```

**Expected**: ComfyUI starts with:
- TORCH_COMPILE=1 (was disabled)
- Optimized CUDA allocator
- SageAttention3 active
- High Performance settings

**Step 2: Load Your Workflow**
- Open your existing workflow
- Run a test generation
- Time both passes
- **Target**: 67-80s per pass (134-160s total for 5s video)

**Step 3: Verify Performance Recovery**

If you're getting 67-80s per pass again:
âœ… Environment fix worked (TORCH_COMPILE=1)

If still getting 114-126s:
- Check nvidia-smi during generation
- Verify GPU isn't throttling (temperature, power)
- Check for background processes

**Step 4: Install Frame Interpolation**
- Via ComfyUI-Manager (easiest)
- Test RIFE first (faster)
- Compare with FILM

**Step 5: Document Results**
After each test, note:
- Generation time per pass
- Total time
- Peak VRAM
- Quality observations
- Any issues

---

## ðŸ“Š Success Metrics

### Performance Targets (From Your Manual Tests):

**Per Pass:**
- âœ… Excellent: 67-80s
- âœ… Good: 80-85s
- âš ï¸ Slow: >85s

**Two-Pass Total (5s video):**
- âœ… Excellent: 134-160s
- âœ… Good: 160-180s
- âš ï¸ Slow: >180s

**With Interpolation (5s @ 32fps):**
- âœ… Target: <180s total
- RIFE: ~150s total (fast)
- FILM: ~170s total (quality)

### Quality Metrics:

- No visible artifacts
- Smooth motion
- Temporal consistency
- Good detail preservation
- Acceptable trade-offs with 4-step LoRA

---

## ðŸ“‚ Complete File Structure

```
ComfyUI/
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ SYSTEM_AUDIT.md (Hardware/software audit)
â”‚   â”œâ”€â”€ SESSION_SUMMARY.md (Session overview)
â”‚   â”œâ”€â”€ TWO_PASS_WORKFLOW.md (Workflow guide)
â”‚   â”œâ”€â”€ WORKFLOW_ANALYSIS.md (Your workflow analysis)
â”‚   â”œâ”€â”€ FRAME_INTERPOLATION_GUIDE.md (RIFE/FILM guide)
â”‚   â”œâ”€â”€ IMPLEMENTATION_GUIDE.md (This file)
â”‚   â”œâ”€â”€ PROGRESS_REPORT.md (Progress tracking)
â”‚   â”œâ”€â”€ NEXT_STEPS.md (Decision points)
â”‚   â””â”€â”€ env_snapshot_rtx5090.json (Environment state)
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ save_env.py (Environment snapshot tool)
â”‚   â”œâ”€â”€ launch_wan22_rtx5090.bat (Your launcher)
â”‚   â”œâ”€â”€ launch_wan22_rtx4090.bat (4090 launcher)
â”‚   â”œâ”€â”€ launch_wan22_a100.bat (A100 launcher)
â”‚   â””â”€â”€ wan22_benchmark.py (Test framework)
â””â”€â”€ workflows/
    â””â”€â”€ wan22_baseline_reference.json (Your workflow copy)
```

---

## ðŸŽ¯ Key Decisions Made

### Based on Your Workflow:

1. **CFG=1.0**: Your workflow uses very low CFG
   - Interesting choice! Should test 3.5 and 7.0 for comparison
   - May be contributing to speed

2. **Advanced Two-Pass**: Using KSamplerAdvanced with overlapping steps
   - Pass 1: steps 0-2 (with noise)
   - Pass 2: steps 2-4 (no noise)
   - Smooth transition strategy

3. **Model Sampling Shift**: Different values per model
   - High noise: shift=5.0
   - Low noise: shift=6.0
   - Controls noise schedule

4. **SageAttention3**: Already enabled
   - Optimal for RTX 5090 Blackwell architecture
   - Should see benefits vs FlashAttention

### Environment Fixes Applied:

1. **TORCH_COMPILE=1**: Was disabled (0), now enabled
   - May restore 67-80s performance
   - Compiles model for efficiency

2. **Optimized CUDA Allocator**:
   ```
   PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:512,expandable_segments:True
   ```

3. **Proper Threading**: `OMP_NUM_THREADS=8`

4. **Lazy Module Loading**: `CUDA_MODULE_LOADING=LAZY`

---

## ðŸ’¡ Recommendations

### Immediate:

1. **Test optimized launch script first**
   - Verify 67-80s performance returns
   - If yes, environment fix worked!

2. **Install frame interpolation ASAP**
   - RIFE for speed
   - FILM for quality
   - Compare both

3. **Document everything**
   - Times, VRAM, quality notes
   - Will inform Docker config

### For Production (Sogni):

1. **Standardize on best interpolator**
   - Likely RIFE for speed
   - FILM if quality demands it

2. **Lock down environment**
   - Use environment snapshots
   - Docker containers for consistency

3. **GPU-specific configurations**
   - Don't assume 5090 config works on 4090
   - Test each GPU tier separately

---

## â“ Troubleshooting

### If Performance Still Slow (>85s per pass):

1. Check GPU utilization:
   ```batch
   nvidia-smi dmon -s u
   ```
   Should see 95-100% during generation

2. Check temperature throttling:
   ```batch
   nvidia-smi dmon -s t
   ```
   If >83Â°C, may throttle

3. Check power limit:
   ```batch
   nvidia-smi -q -d POWER
   ```
   Should see full 600W available

4. Kill background GPU processes:
   ```batch
   nvidia-smi
   # Note any processes, kill if needed
   ```

### If OOM Errors:

1. Reduce batch size to 1 (should already be 1)
2. Use --reserve-vram flag
3. Manually unload model between passes

### If Quality Issues:

1. Test CFG values (1.0 vs 3.5 vs 7.0)
2. Verify LoRAs are loading correctly
3. Check both pass order directions

---

## ðŸŽ“ What We've Learned

### About Your Setup:

- RTX 5090 is perfectly configured
- Your workflow is already well-optimized
- TORCH_COMPILE being disabled likely caused slowdown
- Two-pass with 4-step LoRA is the right approach

### About Wan 2.2 i2v:

- Two models work together (not alternatives)
- 4-step LoRA gives ~8x speedup
- SageAttention3 optimal for Blackwell
- 16fps generation â†’ 32fps interpolation is the way

### For Sogni Distributed Network:

- Need GPU-specific Docker images
- Environment consistency is critical
- 4090 needs careful VRAM management (24GB)
- A100 should use FlashAttention, not SageAttention3

---

## âœ… Ready to Proceed

Everything is set up. You have:

1. âœ… Optimized launch scripts for all GPU tiers
2. âœ… Your workflow analyzed and copied
3. âœ… Complete documentation
4. âœ… Testing framework ready
5. âœ… Environment fixes applied
6. âœ… Clear execution plan

**Next Action**: Start ComfyUI with optimized script and verify performance!

```batch
cd C:\Users\markl\Documents\git\ComfyUI
.\scripts\launch_wan22_rtx5090.bat
```

Then load your workflow and time a test run. If you're back to 67-80s per pass, we've fixed it! ðŸŽ‰

---

*Implementation Guide - Wan 2.2 i2v Optimization for Sogni*  
*Generated: 2025-11-23*

